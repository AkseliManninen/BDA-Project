---
title: "BDA Project"
author: "Anonymous"
output:
  pdf_document:
    toc: yes
    toc_depth: 1
  word_document:
    toc: yes
    toc_depth: '1'
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(aaltobda)
library(tidyverse)
library(latex2exp)
library(loo)
library(bayesplot)
library(posterior)
library(cmdstanr)
library(tidyverse)
library(reshape2)
library(ggcorrplot)
library(kableExtra)
set_cmdstan_path('/coursedata/cmdstan')

```


\newpage
# 1. Project Description and Motivation

Studying the relationship between income and education has been the focus of many studies. The studies have concluded that a strong connection exists between higher education and income (Card, 1999). In general, individuals with stronger education are more likely to be employed and earn a big salary compared to less educated people (Card, 1999). For that reason, education is described as an investment in human capital (Wolla & Sullivan, 2017).

This study examines this phenomenon from the perspective of people that have acquired their education from colleges in the United States. As the connection between education and income has been shown in the existing literature, this study strives to further examine the associations between college related features and income level years after graduation. This project is not limited to only considering educational aspects but expands it to family backgrounds.

In this study, a Bayesian approach is taken to observe the bond between the educational and family related features and earnings in a multivariate linear regression setting. It is in our interest to find out how accurately the selected features can predict future income for the students. Furthermore, finding well-predictive features among the vast number of variables is pursed, and then evaluating predictive performance using these features with selected statistical models.

As this study is conducted in a university environment by university students and presented mainly to other students and faculty, the findings of this study could be especially meaningful for the members of the group and peers on the course.

# 2. Data Description

```{r, include=FALSE}

# read in data sets
data <- read.csv2("./Data/Most-Recent-Cohorts-Institution.csv", sep = ",", fileEncoding="UTF-8-BOM") %>%
  as_tibble()

data.description <- read.csv2("./Data/CollegeScorecardDataDictionary.csv", sep = ",", fileEncoding="UTF-8-BOM") %>%
  as_tibble()

```


```{r, include=FALSE}

# DATA MANIPULATION

# list variables
id.vars <- c("UNITID", "INSTNM", "CITY", "ST_FIPS", "REGION")
numerical.vars <- c("SATVRMID", "SATMTMID", "MD_FAMINC", "AGE_ENTRY", "FEMALE", 
                    "FIRST_GEN", "PCT_WHITE", "DEBT_MDN_SUPP", "C150_4", "COSTT4_A", 
                    "MD_EARN_WNE_P10", "POVERTY_RATE", "UNEMP_RATE", "MARRIED")
categorical.vars <- c("LOCALE", "CCBASIC", "CONTROL")
SAT.vars <- c("SATVRMID", "SATMTMID")

# filter specific school types
schooltype.filter <- seq(14,23)

# create map for variable descriptions
variable.descriptions <- data.description %>%
  select(VARIABLE.NAME, NAME.OF.DATA.ELEMENT, NOTES) %>%
  filter(VARIABLE.NAME %in% c(id.vars, categorical.vars, numerical.vars))

# extract categorical variables
data.categorical <- data %>%
  select(all_of(id.vars), all_of(categorical.vars)) %>%
  mutate(across(.cols = all_of(categorical.vars), .fns = as.factor))

data.categorical.dropna <- data.categorical %>%
  drop_na()

# extract numerical variables
data.numerical <- data %>%
  select(all_of(id.vars), all_of(numerical.vars)) %>%
  mutate(across(.cols = c(id.vars[1], numerical.vars), .fns = as.numeric))

data.numerical.dropna <- data.numerical %>%
  drop_na()

# aggregate SAT scores
data.numerical.dropna <- data.numerical.dropna %>%
  mutate(SAT_ALL = data.numerical.dropna %>%
           select(SATVRMID, SATMTMID) %>%
           rowMeans()
         )

data.joined <- data.numerical %>%
  inner_join(data.categorical, by = id.vars) %>%
  filter(CCBASIC %in% schooltype.filter)

data.joined.dropna <- data.numerical.dropna %>%
  inner_join(data.categorical.dropna, by = id.vars) %>%
  filter(CCBASIC %in% schooltype.filter)

categorical.vars.data <- data.joined.dropna %>%
  select(all_of(categorical.vars), MD_EARN_WNE_P10) %>%
  relocate(MD_EARN_WNE_P10, 1)


data.joined <- data.numerical %>%
  inner_join(data.categorical, by = id.vars) %>%
  filter(CCBASIC %in% schooltype.filter)

data.joined.dropna <- data.numerical.dropna %>%
  inner_join(data.categorical.dropna, by = id.vars) %>%
  filter(CCBASIC %in% schooltype.filter)

```


```{r, include=FALSE}

# make variable type specific data frames for plots etc.
numerical.vars.data <- data.joined.dropna %>% 
  select(!c(id.vars, SAT.vars, categorical.vars)) %>%
  relocate(MD_EARN_WNE_P10, 1)

categorical.vars.data <- data.joined.dropna %>%
  select(all_of(categorical.vars), MD_EARN_WNE_P10) %>%
  relocate(MD_EARN_WNE_P10, 1)

```

The used dataset is the most recent institutional-level college scorecard data from the US Department of Education^[Available at: https://collegescorecard.ed.gov/data]. The institutional-level dataset contains aggregate data for each educational institution and includes data on institutional characteristics, enrollment, student aid, costs and student outcomes. The dataset has 6681 observations on 2989 variables.

This dataset was chosen because it seemed to provide information that could answer interesting education-related questions in the project, and also because the dataset has a large number of observations and a large number of variables. The large amount of variables permits for a lot of flexibility when it comes to modelling with the data and also having enough data is important in order to be able to make valid inferences. 

After investigating the dataset, the most intriguing analysis problem was to study how college related factors affect
t the median earnings of alumni 10 years after entry, which is our dependent variable:

$$
\begin{tabular} {lll} 
Name & Data type & Description \\
\hline
MD\_EARN\_WNE\_P10 & double & Median earnings of students 10 years after entry
\end{tabular}
$$

In the next section, we outline how features were selected 

# 3. Feature Selection

The initial data set has almost 3000 features, which is a large number compared to the total number of observations of 6681. Moreover, there are many missing values for certain variables in the dataset and not all variables are interesting when trying to predict future earnings. For these reasons, there was a clear need to prune down features.

We conducted feature selection in three phases: in the first phase, a subset of features was selected based on features commonly used in previous studies that have examined the relationship between educational factors and earnings. Moreover, we used common sense when trying to come up with additional interesting features that could predict future earnings. In the second phase, we assessed the relationship of the features with our dependent variable, and accounted for any multicollinearity arising from mutually correlated features. Furthermore, we visualized categorical variables and engineered new features to be added to the model. In the last phase, we utilized stepwise regression in streamlining our model to include only the most significant features in terms of the Akaike Information Criterion (AIC).

## Phase 1 - Feature selection based on literature and common sense

The initial set of features chosen based on past literature and common sense is outlined in the table below: 

$$
\begin{tabular} {r|l|l|l} 
& Name & Data type & Description \\ 
\hline
1 & SATVRMID & integer & Midpoint of SAT scores at the institution (critical reading) \\
2 & SATMTMID & integer & Midpoint of SAT scores at the institution (math) \\
3 & SATWRMID & integer & Midpoint of SAT scores at the institution (writing) \\
4 & MD\_FAMINC & double & Median family income \\
5 & AGE\_ENTRY & double & Average age of entry \\
6 & FEMALE & double & Share of female students \\
7 & FIRST\_GEN & double & Share of first-generation students \\
8 & PCT\_WHITE & double & Percent of the population from students' zip codes that is White \\
9 & DEBT\_MDN\_SUPP & integer & Median debt, suppressed for n=30 \\
10 & C150\_4 & double & Completion rate for first-time, full-tim students \\
11 & COSTT4\_A & integer & Average cost of attendance (academic year institutions) \\
12 & POVERTY\_RATE & double & Poverty rate \\
13 & UNEMP\_RATE & double & Unemployment rate \\
14 & MARRIED & double & Share of married students \\
15 & VETERAN & double & Share of veteran students \\
16 & LOCALE & categorical & Locale of institution \\
17 & CCBASIC & categorical & Carnegie Classification -- basic \\
18 & CONTROL & categorical & Control of institution
\end{tabular}
$$

SAT scores were combined as one variable, because they were highly correlated and could easily be viewed as one entity. However, writing SAT scores had too few observations due to discontinued tracking. Therefore, a variable SAT_ALL was formed by summing the math and critical thinking SAT scores. After this, we have a total of 793 observations for these features. 

Descriptive statistics for the resulting numerical variables can be found from the table below. Min is the minimum, 1st Qu. is the 1st quartile, Median is the median, Mean is the arithmetic mean, 3rd Qu. is the 3rd quartile, Max is the maximum and St.dev is the sample standard deviation.

```{r, echo=FALSE}

stats.data <- numerical.vars.data

stats <- stats.data %>% apply(2, summary) %>% t() %>% as.data.frame()
stats$St.dev <- stats.data %>% apply(2, sd)
kable(stats, format = "latex", align = "lrrrrrrr", digits = 2, col.names = c("Min", "1st Qu.", "Median", "Mean", "3rd Qu.", "Max", "St.dev")) %>% 
  row_spec(0, bold = T) %>% 
  kable_styling(latex_options = "HOLD_position", position = "left")

```

The table shows that our dependent variable - median earnings 10 years after entry - range from \$24.2k to \$103.2k. Overall one can see that there is great variation in almost all features as well. For example, age of entry varies from 19.6 to 33.8,  average composite SAT scores range from 395 to 760, and cost of attendance varies from \$11.7k to \$79.8k, to name a few interesting details. 

## Phase 2 - Feature Selection with Correlation and Linear Association

In the second phase of feature selection, a subset of features was selected from the 18 variables resulting from the first phase. We examined the correlations between the dependent variable and the features as well as between-features correlations. Moreover, we examined whether there were any linear relationships between the features and the dependent variable. Lastly, we visually examined categorical variables and engineered new features that we believed to have predictive ability over future earnings.

### Numerical Variables

#### Correlation Analysis

The figure below shows the (Pearson's) correlation matrix for the dependent variable and the features.

```{r, echo=FALSE, fig.align='center'}

ggcorrplot(cor(numerical.vars.data),
          lab = TRUE,
          lab_size = 2,
          title = "Correlations",
          tl.cex = 8)

```

The correlation matrix shows on the bottom row that SAT scores, cost of attendance, and family income are the most positively correlated features with our dependent variable. The respective correlations are 0.76, 0.75, and 0.52. Most negatively correlated features are the percentage of first generation students, poverty rate, and average age of entry with respective correlations of -0.45, -0.4, and -0.31. These are interesting observations and make intuitive sense.

#### Bivariate Plotting

The panel of figures below show scatter plots between the dependent variable and all numerical features.

```{r, echo=FALSE, fig.height=12, fig.width=12, fig.align='center'}

melted.numerical.vars.data <- melt(numerical.vars.data, id.vars = "MD_EARN_WNE_P10")

melted.numerical.vars.data <- melt(numerical.vars.data, id.vars = "MD_EARN_WNE_P10")
ggplot(melted.numerical.vars.data, aes(x = value, y = MD_EARN_WNE_P10)) + 
  facet_wrap(~variable, scales = "free", ncol = 3) +
  geom_point(shape=20, color="black") +
  ggtitle("Median earnings after 10 years and the independent variables") +
  xlab("Feature value") + ylab("Median earnings")

```

The figures show that many of the features exhibit a linear like relationship with the dependent variable. Especially, SAT scores (SAT_ALL) show a clear linear association. Other features that show a linear trend are e.g., family income (MD_FAMINC), completion rate (C140_4), and the percentage of first generation students (FIRST_GEN). There are hints of some non-linear relationships as well, e.g., poverty rate appears to have a convex non linear relationship with the dependent variable. Cost of attendance (COSTT4_A), on the other hand, suggests that there could be two groups, perhaps cheaper public school and private school.

#### Concluding Remarks

Based on the analysis presented thus far, we selected the following numerical variables: SAT_ALL (median sum of math and critical thinking SAT scores), MD_FAMINIC (median family income of the student), AGE_ENTRY (median age of starting at the college), COSTT4_A (median cost of college), and POVERTY_RATE (poverty rate in the area the college is located).

After including the obvious features, such as SAT scores, we included features with the following reasoning: if the correlation between a feature and the dependent variable was low and there was no observable dependency between the two in the scatter plot, the feature was excluded. Furthermore, to avoid multicollinearity, we removed features that were highly correlated with other independent variables, especially if they were not clearly correlated with the dependent variable and we couldn't form a believable hypothesis for the mechanism through which that variable affected income after college.

### Categorical Variables

#### Box Plots

The categorical variables were visualized with box plots to assess if income after college differs among the categories.


```{r, include=FALSE}

# categorical variable box plots
melted.categorial <- melt(categorical.vars.data, id.vars = "MD_EARN_WNE_P10")
melted.categorial.ccbasic <- melted.categorial %>% as_tibble() %>% filter(variable=="CCBASIC")
melted.categorial.control <- melted.categorial %>% as_tibble() %>% filter(variable=="CONTROL")
melted.categorial.locale <- melted.categorial %>% as_tibble() %>% filter(variable=="LOCALE")

```

The figure below shows the median earnings for different university types. CCBASIC stands for the Carnegie Classification for the university.

```{r, echo=FALSE}
ggplot(melted.categorial.ccbasic, aes(x=value, y=MD_EARN_WNE_P10, fill=value)) +
  geom_boxplot() +
  geom_jitter(color="black", size=0.4, alpha=0.9) +
  theme(
    legend.position="none",
    plot.title = element_text(size=11)
  ) +
  ggtitle("University types") +
  xlab("CCBASIC") +
  labs(caption = "Doctoral (15-17), Master's (18-20), Bachelor's (21-23)")

```
Based on the plot, CCBASIC was divided into two dummy variables: MASTER and DOCTORAL. These variables represent if the college is classified as Master's college and university or Doctoral's college and university. If a college does not belong to either of those, it is a Bachelor's college and university. Other special focus colleges and universities were discarded from the dataset to keep the model simpler and to avoid unnecessary outliers due to unconventional nature of some very specialized colleges. Our model does not attempt to provide accurate predictions for specialized colleges.


The figure below shows the median earnings for different university locations. LOCALE specifies whether the unversity locates in a metropolis, city, suburb, town, or a rural area.

```{r, echo=FALSE, out.width = "70%"}

ggplot(melted.categorial.locale, aes(x=value, y=MD_EARN_WNE_P10, fill=value)) +
  geom_boxplot() +
  geom_jitter(color="black", size=0.4, alpha=0.9) +
  theme(
    legend.position="none",
    plot.title = element_text(size=11)
  ) +
  ggtitle("Location of school") +
  xlab("LOCALE") +
  labs(caption = "City (11-13), Suburb (21-23), Town (31-33), Rural (41-43)")

```

Based on figure, we engineered a new dummy variable URBAN, which takes the value 1 if the university LOCALE is not classified as Rural.

The categorical variable CONTROL had three classes: public, for-profit private and nonprofit private. The figure below shows the median earnings depending on the control status.

```{r, echo=FALSE, out.width = "70%"}

ggplot(melted.categorial.control, aes(x=value, y=MD_EARN_WNE_P10, fill=value)) +
  geom_boxplot() +
  geom_jitter(color="black", size=0.4, alpha=0.9) +
  theme(
    legend.position="none",
    plot.title = element_text(size=11)
  ) +
  ggtitle("Public vs. Private") +
  xlab("CONTROL") +
  scale_x_discrete(labels = c("Public","Private","Non-profit private"))

```

Based on the figure, CONTROL was modified into a dummy variable PRIVATE, which takes the value 1 if the school is privately controlled (either for profit or non profit).

The selected categorical variables were: URBAN, DOCTORAL, MASTER, PRIVATE.

In the third and final phase, all remaining variables were used with stepwise regression to test which subset of features perform the best, whether the received coefficients are reasonable, and if there are signs of overfitting.

The stepwise regression suggested using all of the variables, except AGE ENTRY and DOCTORAL. The output of the stepwise regression can be found in the Appendix. Because stepwise regression suggested leaving out DOCTORAL, for the sake of consistency we decided to also leave out MASTER as it was a the middle level in our institutional classifications and wouldn't have made much sense on its own. To test whether AGE ENTRY would be included by stepwise after removing MASTER and DOCTORAL, stepwise was ran again. Even then, AGE ENTRY was discarded from the model and the other variables remained the same.

The final features are listed in the table below:


$$
\begin{tabular} {rlll} 
& Name & Data type & Description \\
\hline
1 & SAT\_ALL & float & Midpoint of SAT scores at the institution (critical reading ,math) \\
2 & MD\_FAMINC & float & Median family income \\
3 & COSTT4\_A & float & Average cost of attendance (academic year institutions) \\
4 & POVERTY\_RATE & float & Poverty rate \\
5 & URBAN & binary & Urban or rural area \\
6 & PRIVATE & binary & Private or public school \\
\end{tabular}
$$
MD_EARN_WNE_P10 ~ SAT_ALL + MD_FAMINC + COSTT4_A + 
    POVERTY_RATE + URBAN + PRIVATE

# 3. Model Descriptions

**MATEMATIIKKA TARKISTETTAVA**

## Description of the separate model

In the separate model, posteriors for the parameters are constructed. In
the context of the project, the separate model considers all regions independent
from each other, meaning that each region have individual parameters (mu, sigma).

Mathematical description:

$y_{ij}|\mu_j, \sigma_j \sim \mathcal{N}(\mu_j, \sigma_j^2)$ 

where $\mu_j = \alpha_j+\bf{\beta_j X}$

The parameters of the parameter vector are given in the section 4 with their
priors.

## Description of the pooled model

As in the separate model, the pooled model constructs posteriors for the 
parameters. However, the regions are considered as one entity meaning that
all regions share the same distribution and parameter values.

Mathematical description:

$y_i|\mu, \sigma \sim \mathcal{N}(\mu, \sigma^2)$

where $\mu = \alpha+\bf{\beta X}$

The parameters of the parameter vector are given in the section 4 with their
priors.

## Description of the hierarchical model

Contrary to the other two models, in the hierarchical model posteriors
are constructed for the prior parameters. With the hierarchical model,
the regions are considered as individual but similar. In the context of the
project, the regions share same sigma and the parameters forming mu are similarly
distributed (sharing the hyperparameters).

Mathematical description:

$y_{ij} | \mu_j \sim \mathcal{N}(\mu_j, \sigma^2)$

where $\mu_j|\mu_P, \sigma_P^2 \sim \mathcal{N}(\mu_P, \sigma_P^2)$

The hyperparameters and parameters are given in the section 4 with their priors.

## Description of the linear model

**MIKÄ TÄÄ ON? JOS JÄÄMÄSSÄ, NIIN TÄYDENNETTÄVÄ**

# 4. Choice of Priors

We use weakly informative priors, as we do not posses enough information about the 
dependency between the independent variables and the dependent variable. 
When selecting the priors, proper distribution type was considered for each variable. 
The prior standard deviations were selected based on the magnitude of absolute values 
of the variables and what kind of impact they could have for income, with loose enough
estimates to avoid limiting the values too much. Alternative approach could have been 
to standardize all variables, which would have reduced the need to think about magnitudes
of absolute values.

SAT_ALL ~ Normal(43, 500)

Justification: We agreed that it was somewhat reasonable to expect scores in the SAT 
exam to be associated with higher income. Due to our approach of using weakly informative 
priors, we set a high standard deviation, but set a positive mean due to expected positive
association.

The mean is calculated with the following formula: Median individual income
in the United States / Average SAT Score (math and writing).

The median individual income in the US was approximately 31 000 in 2020 
(Data Commons, 2020). The average SAT score in the US in 2020 were 523 in Math
and 582 in Evidence-Based Reading and Writing (Number2, 2020).

mu = 31 000 / (523 + 528/2) = 43.2

MD_FAMINIC ~ Normal(0, 100)

Justification: Weakly informative prior is again selected as we don't posses enough 
information on the dependency. The absolute values are in general high, 
(for example compared to AGE_OF_ENTRY) and thus the standard deviation is set 
lower for this variable. However, there could be cases where MD_FAMINIC is low, 
due to for example unemployment, so the standard deviation is still set 
considerably high.

COSTT4_A ~ Normal(0, 500)

Justification: Weakly informative prior is selected as we don't posses enough 
information on the dependency. The average cost per academic year is likely to take lower
values than median family income, but higher values than average age of entry and thus 
the standard deviation is set between the standard deviations of those.

POVERTY_RATE ~ Normal(0, 2500)

Justification: The possible values are between 0 and 100. There could be situations were poverty rate in an area is really low, for instance 0.5%. For that reason, the standard deviation in the prior is set high to enable possibly high weight for a small value.

URBAN ~ Normal(0, 2500)

Justification: We don't have a strong expectation of direction or magnitude of effect on income. 
As the age of entry could be somewhere in the range of 15 - 50 without considering outliers, 
a few dozen years difference could have dramatic changes in income either way, the standard
deviation is set high.


PRIVATE ~ Normal(0, 2500)

Justification: For MASTER and PRIVATE weakly informative prior, is selected as 
we don't posses enough information on the dependency with the dependent variable.
Because the values are always either 0 and 1, the standard deviation is set
high.

# 5. Stan Code

**TÄHÄN JOTAIN TRAIN TEST SPLITISTÄ?**

```{r, include=FALSE}

data.joined.model <- data.joined.dropna %>%
  mutate(URBAN = case_when(LOCALE %in% c(seq(11,13), seq(21,23)) ~ 1,
                           TRUE ~ 0),
         PRIVATE = case_when(CONTROL %in% c(2,3) ~ 1,
                             TRUE ~ 0),
         DOCTORAL = case_when(CCBASIC %in% seq(15,17) ~ 1,
                              TRUE ~ 0),
         MASTER = case_when(CCBASIC %in% seq(18,20) ~ 1,
                            TRUE ~ 0)
  )

numerical.vars.model <- c("MD_EARN_WNE_P10", "SAT_ALL", "MD_FAMINC", "AGE_ENTRY", 
                          "COSTT4_A", "POVERTY_RATE")
categorical.vars.model <- c("URBAN", "PRIVATE", "DOCTORAL", "MASTER")

# data with REGION identifier for STAN
data.joined.stan <- data.joined.model %>%
  select(REGION, numerical.vars.model, categorical.vars.model)

data.joined.stan.test <- data.joined.stan %>% 
  sample_n(30)

data.joined.stan <- data.joined.stan %>% 
  setdiff(data.joined.stan.test)

# data for linear regression model in R
data.joined.model <- data.joined.stan %>%
    select(-REGION)

```

We used cmdstanr for our models. Source code for all three models can be found in in the Appendix.

## Separate model

Summary of model fit for main parameters:

```{r, include=FALSE, results = "hide", warning=FALSE}

separate.model <- cmdstan_model(stan_file = "./Stan/separate.stan")

separate.model.data <- list(N = nrow(data.joined.stan),
                            K = length(unique(data.joined.stan$REGION)),
                            x = data.joined.stan$REGION,
                            
                            SAT_ALL = data.joined.stan$SAT_ALL,
                            MD_FAMINIC = data.joined.stan$MD_FAMINC,
                            COSTT4_A = data.joined.stan$COSTT4_A,
                            POVERTY_RATE = data.joined.stan$POVERTY_RATE,
                            URBAN = data.joined.stan$URBAN,
                            PRIVATE = data.joined.stan$PRIVATE,
                            y = data.joined.stan$MD_EARN_WNE_P10,
                            
                            pm_alpha = 0,
                            ps_alpha = 10000,
                            pm_SAT_ALL = 50,
                            ps_SAT_ALL = 500,
                            pm_MD_FAMINC = 0,
                            ps_MD_FAMINC = 100,
                            pm_COSTT4_A = 0,
                            ps_COSTT4_A = 500,
                            pm_POVERTY_RATE = 0,
                            ps_POVERTY_RATE = 2500,
                            pm_URBAN = 0,
                            ps_URBAN = 2500,
                            pm_PRIVATE = 0,
                            ps_PRIVATE = 2500,
                            pm_sigma = 10000,
                            ps_sigma = 10000
                            
)


separate.fit <- separate.model$sample(data = separate.model.data, seed = 1234, refresh = 1e3)

separate.fit$summary()

```

## Pooled model

Summary of model fit for main parameters:

```{r, results = "hide", warning=FALSE}

pooled.model <- cmdstan_model(stan_file = "./Stan/pooled.stan")

pooled.model.data <- list(N = nrow(data.joined.stan),
                          
                          SAT_ALL = data.joined.stan$SAT_ALL,
                          MD_FAMINIC = data.joined.stan$MD_FAMINC,
                          COSTT4_A = data.joined.stan$COSTT4_A,
                          POVERTY_RATE = data.joined.stan$POVERTY_RATE,
                          URBAN = data.joined.stan$URBAN,
                          PRIVATE = data.joined.stan$PRIVATE,
                          y = data.joined.stan$MD_EARN_WNE_P10,
                          
                          pm_alpha = 0,
                          ps_alpha = 10000,
                          pm_SAT_ALL = 50,
                          ps_SAT_ALL = 500,
                          pm_MD_FAMINC = 0,
                          ps_MD_FAMINC = 100,
                          pm_COSTT4_A = 0,
                          ps_COSTT4_A = 500,
                          pm_POVERTY_RATE = 0,
                          ps_POVERTY_RATE = 2500,
                          pm_URBAN = 0,
                          ps_URBAN = 2500,
                          pm_PRIVATE = 0,
                          ps_PRIVATE = 2500,
                          pm_sigma = 10000,
                          ps_sigma = 10000
                          
                          )


pooled.fit <- pooled.model$sample(data = pooled.model.data, seed = 1234, refresh = 1e3)

pooled.fit$summary()

```

## Hierarchical model

Summary of model fit for main parameters:

```{r, echo=FALSE, results = "hide", warning=FALSE}

hierarchical.model <- cmdstan_model(stan_file = "./Stan/hierarchical.stan")

hierarchical.model.data <- list(N = nrow(data.joined.stan),
                                K = length(unique(data.joined.stan$REGION)),
                                x = data.joined.stan$REGION,
                            
                                SAT_ALL = data.joined.stan$SAT_ALL,
                                MD_FAMINIC = data.joined.stan$MD_FAMINC,
                                COSTT4_A = data.joined.stan$COSTT4_A,
                                POVERTY_RATE = data.joined.stan$POVERTY_RATE,
                                URBAN = data.joined.stan$URBAN,
                                PRIVATE = data.joined.stan$PRIVATE,
                                y = data.joined.stan$MD_EARN_WNE_P10,
                                
                                pm_alpha = 0,
                                ps_alpha = 10000,
                                pm_s_alpha = 100,
                                ps_s_alpha = 100,
                                
                                pm_SAT_ALL = 43,
                                ps_SAT_ALL = 500,
                                pm_s_SAT_ALL = 100,
                                ps_s_SAT_ALL = 100,
                                
                                pm_MD_FAMINC = 0,
                                ps_MD_FAMINC = 100,
                                pm_s_MD_FAMINC = 10,
                                ps_s_MD_FAMINC = 100,
                                
                                pm_COSTT4_A = 0,
                                ps_COSTT4_A = 500,
                                pm_s_COSTT4_A = 50,
                                ps_s_COSTT4_A = 500,
                                
                                pm_POVERTY_RATE = 0,
                                ps_POVERTY_RATE = 2500,
                                pm_s_POVERTY_RATE = 500,
                                ps_s_POVERTY_RATE = 500,
                                
                                pm_URBAN = 0,
                                ps_URBAN = 2500,
                                pm_s_URBAN = 500,
                                ps_s_URBAN = 500,
                                
                                pm_PRIVATE = 0,
                                ps_PRIVATE = 2500,
                                pm_s_PRIVATE = 500,
                                ps_s_PRIVATE = 500,
                                
                                pm_sigma = 10000,
                                ps_sigma = 10000,
                                pm_s_sigma = 500,
                                ps_s_sigma = 500)

hierarchical.fit <- hierarchical.model$sample(data = hierarchical.model.data, 
                                              seed = 1234, refresh = 1e3)

hierarchical.fit$summary()

```


# 6. Stan Specifications

We used the following Stan options:

- Seed: 1234

- Chains: 4

- Iterations per chain: 2000

# 7. Convergence Diagnostics (rhat, ESS, divergences) and what was done if the convergence was not good with the first try.

## Rhat

We used the rhat() function for all models to get the rhat convergence diagnostic. The function compares the between chain and within chain
estimates for model parameters and other univariate quantities of interest. If the between chain and within chain estimates agree, it is said
that the chains have mixed well. This happens when R-hat is less than 1.05 or less than 1.01 depending on the standard. We decided not be strict
with our multivariate model and chose the less strict threshold of 1.05.

### Separate model

```{r}

rhat.df <- tibble()

params <- c("alpha[1]", "beta_SAT_ALL[1]", "beta_MD_FAMINIC[1]", "beta_COSTT4_A[1]", 
            "beta_POVERTY_RATE[1]", "beta_URBAN[1]", "beta_PRIVATE[1]")

for (param in params) {
  rhats <- extract_variable_matrix(separate.fit$draws(), variable = param) %>% apply(2, rhat)
  row <- tibble("Parameter" = param, 
                "Chain 1" = rhats[1], 
                "Chain 2" = rhats[2], 
                "Chain 3" = rhats[3], 
                "Chain 4" = rhats[4])
  rhat.df <- rbind(rhat.df, row)
}

rhat.df

``` 


### Pooled model

```{r}

params <- pooled.model$variables()$parameters %>% names()
rhat.df <- tibble()
for (param in params) {
  rhats <- extract_variable_matrix(pooled.fit$draws(), variable = param) %>% apply(2, rhat)
  row <- tibble("Parameter" = param, 
                "Chain 1" = rhats[1], 
                "Chain 2" = rhats[2], 
                "Chain 3" = rhats[3], 
                "Chain 4" = rhats[4])
  rhat.df <- rbind(rhat.df, row)
}
rhat.df

```


### Hierarchical model

```{r}

rhat.df <- tibble()

params <- c("alpha[1]", "beta_SAT_ALL[1]", "beta_MD_FAMINIC[1]", "beta_COSTT4_A[1]", 
            "beta_POVERTY_RATE[1]", "beta_URBAN[1]", "beta_PRIVATE[1]")

for (param in params) {
  rhats <- extract_variable_matrix(hierarchical.fit$draws(), variable = param) %>% apply(2, rhat)
  row <- tibble("Parameter" = param, 
                "Chain 1" = rhats[1], 
                "Chain 2" = rhats[2], 
                "Chain 3" = rhats[3], 
                "Chain 4" = rhats[4])
  rhat.df <- rbind(rhat.df, row)
}

rhat.df

``` 

## Effective sample size (ESS)

Effective sample size (ESS) evaluates the uncertainty in estimates that is caused 
by autocorrelation of the chains. The value of effective sample size represents 
the number of independent samples that poses the same predictive power as all 
the autocorrelated samples. In other words, if the number of effective sample 
size is high, then the number of independent samples is high. (Stan Reference Manual, n.d).

As can be seen on the tables below, for the separate model the values for 
the first region are range from 54 to 96. In this region, there are the sample
size N is xxx. This means that...

For the pooled model the ESS values for parameters range from 508 to 954. 
This means that most of the samples for all parameters are independent, although
there is also autocorrelation in most cases. According to (Stan) if the
effective sample size is larger than the number of samples, this can be due
to antithetic Markov Chains which have negative autocorrelations on odd lags.

For the hierarchical model the ESS values for parameters are between 266 and
1080. This means that for some parameters there samples are more autocorrelated
samples than independent ones. The analysis for the highest values is the
same as for pooled.

### Separate Model

```{r}

params <- separate.model$variables()$parameters %>% names()
ess.df <- tibble()

params <- c("alpha[1]", "beta_SAT_ALL[1]", "beta_MD_FAMINIC[1]", "beta_COSTT4_A[1]", 
            "beta_POVERTY_RATE[1]", "beta_URBAN[1]", "beta_PRIVATE[1]")

for (param in params) {
  ess <- extract_variable_matrix(separate.fit$draws(), variable = param) %>% apply(2, ess_basic)
  row <- tibble("Parameter" = param, 
                "ESS" = ess)
  ess.df <- rbind(ess.df, row)
}
ess.df <- ess.df  %>% group_by(Parameter) %>% summarise(ESS = sum(ESS)/n(),)

ess.df


``` 


## Pooled Model

```{r}

params <- pooled.model$variables()$parameters %>% names()
ess.df <- tibble()

for (param in params) {
  ess <- extract_variable_matrix(pooled.fit$draws(), variable = param) %>% apply(2, ess_basic)
  row <- tibble("Parameter" = param, 
                "ESS" = ess)
  ess.df <- rbind(ess.df, row)
}
ess.df <- ess.df  %>% group_by(Parameter) %>% summarise(ESS = sum(ESS)/n(),)

ess.df

``` 

## Hierarchical Model

```{r}

params <- hierarchical.model$variables()$parameters %>% names()
ess.df <- tibble()

params <- c("alpha[1]", "beta_SAT_ALL[1]", "beta_MD_FAMINIC[1]", "beta_COSTT4_A[1]", 
            "beta_POVERTY_RATE[1]", "beta_URBAN[1]", "beta_PRIVATE[1]")

for (param in params) {
  ess <- extract_variable_matrix(hierarchical.fit$draws(), variable = param) %>% apply(2, ess_basic)
  row <- tibble("Parameter" = param, 
                "ESS" = ess)
  ess.df <- rbind(ess.df, row)
}
ess.df <- ess.df  %>% group_by(Parameter) %>% summarise(ESS = sum(ESS)/n(),)

ess.df


``` 

## HMC specific convergence diagnostics for all models

HMC specific convergence diagnostics were analysed for all models. The R code
and output for diagnostics can be found from the appendix. Based on the HMC specific 
convergence diagnostics, the separate model reached the initial maximum treedepth of 10 
in 100% of the transitions. The diagnostics state that this leads to premature 
termination of trajectories and slow exploration. The proposed action of increasing the 
limit was tested, but it resulted to too long running time for the already time 
consuming fitting of the separate model. The rest of the diagnostics consisting 
of divergences, E-BMFI, effective samplesize and split R-hat satisfactory.

For the pooled model, treedepth, divergences, E-BFMI, effective sample size and 
split R-hat were satifactory.

For the hierarchical model, only 4 out of 4000 hit the maximum treedepth and
23 out of 4000 transitions did not converge. Due to relatively low numbers
(0.1% and 0.57%) no actions were taken for the hierarchical model. The rest 
of the diagnostics were satisfactory.

# 8. Posterior Predictive Checks and Model Comparison

## Posterior Predictive Checks

When doing posterior predictive checking we look for systematic discrepancies between the real observations 
and the data we get from simulating replicated data under the fitted model (Gelman and Hill, 2006). Posterior 
predictive checking is a form of internal validation that is a helpful phase of model building and checking 
in assessing whether our fitted model makes sense.

When comparing the densities of y (real sample values) and y_rep (Stan normal_rng generated values)
in the graphs below, it looks like that y and y_rep are aligning quite well,
with all three models, although it seems that the y_rep values are on average
somewhat more on right (higher estimates for earnings). There are also intervals
where y is suddenly changing direction, which are not visible in y_rep values.


```{r, out.width = "70%"}

separate.extract <- separate.fit$draws(variable = "y_rep")

y <- data.joined.stan$MD_EARN_WNE_P10

y_rep <- matrix(data = separate.extract[,1,], nrow = 1000)

separate.ppctitle <- ggtitle("Separate model",
                             "Comparing densities of y and y_rep")

ppc_dens_overlay(y, y_rep) + separate.ppctitle

# Pooled

pooled.extract <- pooled.fit$draws(variable = "y_rep")

y_rep <- matrix(data = pooled.extract[,1,], nrow = 1000)

pooled.ppctitle <- ggtitle("Pooled model",
                             "Comparing densities of y and y_rep")

ppc_dens_overlay(y, y_rep) + pooled.ppctitle

# Hierarchical

hierarchical.extract <- hierarchical.fit$draws(variable = "y_rep")

y_rep <- matrix(data = hierarchical.extract[,1,], nrow = 1000)

hierarchical.ppctitle <- ggtitle("Hierarchical model",
                             "Comparing densities of y and y_rep")

ppc_dens_overlay(y, y_rep) + hierarchical.ppctitle

```


 
## LOO (Model comparison)

LOO elpd_loo is an estimate of the expected log pointwise pridictive dentisty (ELPD).
elpd_loo sums individual pointwise log predictive densities (Stan Reference Manual, n.d).

Based on elpd_loo the model with the highest value should be selected (highest
ELPD). From the tables below we can observe that separate model has the highest
elpd_loo value, hierarchical model the second highest value, and the pooled the
lowest value. For that reason, separate model is suggested by elpd_loo although
the value of hierachical model comes quite close.


```{r, warning = FALSE}

separate.loo <- separate.fit$loo()

pooled.loo <- pooled.fit$loo()

hierarchical.loo <- hierarchical.fit$loo()

loo_compare(separate.loo, pooled.loo, hierarchical.loo)

``` 

## K hat

In general, if $\hat{k}$ values are greater than 0.7 the PSIS-LOO estimates
might be too optimistic (biased), and on the contrary, if the $\hat{k}$ values
are smaller than 0.7 the estimated can be considered reliable. (Gabry, Gelman, Vehtari, 2016)

As can be observed from the graphs "Separate mode PSIS diagnostics",
"Pooled model PSIS diagnostics" and "Hierarchical model PSIS diagnostics"
for separate model all $\hat{k}$ values are smaller than 0.7, for hierarchical
only one value $\hat{k}$ is greater than 0.7. This means that PSIS-LOO estimates
for these models can be considered reliable. However, for pooled model there
are many $\hat{k}$ values that are a lot greater than 0.7. This indicates
that this model may be biased and the estimates might not be reliable.

The more precise diagnostics for $\hat{k}$ are available in appendix.

```{r, warning=FALSE, out.width = "70%"}

plot(separate.fit$loo(), main = "Separate model PSIS diagnostics")
  
plot(pooled.fit$loo(), main = "Pooled model PSIS diagnostics")

plot(hierarchical.fit$loo(), main = "Hierarchical model PSIS diagnostics")

``` 

# 9. Predictive Performance Assessment

## Root Mean Squared Error (RMSE)

We use RMSE for assessing the predictive ability of our model. The assessment was conducted as follows. First we split the complete data set of 793 observations into a training set of 763 observations and a test set of 30 observations. Second we fit the models to the training set. Then we use the median of the posterior distribution for each parameter in our model to predict the dependent variable based on the values of the independent variables in the test set. Lastly, after obtaining the predicted values, we calculate the RMSE with respect to the actual observed values of the dependent variable in the test set.

### Pooled model

```{r}

pooled.fit.coeff.df <- pooled.fit$summary() %>% slice(2:8)

alpha.hat <- pooled.fit.coeff.df %>% head(1) %>% select(median)
beta.hat <- pooled.fit.coeff.df %>% tail(-1) %>% select(median) %>% as.matrix()

test.X <- data.joined.stan.test %>% 
  select(SAT_ALL, MD_FAMINC, AGE_ENTRY, COSTT4_A, POVERTY_RATE, PRIVATE) %>% 
  as.matrix()

N <- nrow(data.joined.stan.test)
y.hat <- numeric(N)
y <- data.joined.stan.test$MD_EARN_WNE_P10
se <- numeric(N)
for (i in 1:N) {
  
  y.hat[i] <- alpha.hat+beta.hat%*%test.X[i,]
  se[i] <- (y.hat[[i]]-y[i])^2
  
}

y.hat <- y.hat %>% 
  as.matrix()

```

Plot of squared errors:

```{r, eval=FALSE}

se %>% plot(type="b", pch=20)

```

RMSE:

```{r, eval=FALSE}
rmse <- sqrt(mean(se))
rmse

```

# 10. Prior Sensitivity Analysis

To test whether our results are sensitive to prior choices, and to see how changing the priors affects our results, we ran all the models with both wider and narrower priors. The wide priors were obtained by multiplying each standard deviation by three, and the narrow priors were obtained by dividing the original priors by two.

For the separate model...


For the pooled model, when scaling sigma values with 3, there were only minor changes in the beta values. When scaling sigma values with 0.5 the results stayed also about the same, except for beta_PRIVATE whose mean increased from around -7000 to around -5000. Based on these results, it seems that pooled model is not that sensitive for prior changes of this magnitude. 

For the hierarchical model, when scaling sigma values with3, there were bigger differences compared to the pooled model. As an example alpha mean values for decreased in some regions a lot, and at the extreme over 3 times the original value. When scaling sigma values with 0.5, the narrower distribution brought the values closer to the mean values. Although some beta mean and standard deviation values for some regions stayed approximately the same, the change in the priors was clear. For that reason, the hierarchical model is sensitive for prior changes of this magnitude, and more sensitive compared to the pooled model.

In conclusion, the separate and the hierarchical models had a lot of sensitivity for changes in priors compared to the pooled model. The robustness of the pooled model could be explained by the fact that regions are considered in this model as one entity and there are more samples for this one entity compared to separate regions.

## Separate model

Summary of model fit for main parameters with wide priors:

```{r, echo=FALSE,results = "hide", eval=FALSE}
separate.model <- cmdstan_model(stan_file = "./Stan/separate.stan")

scale_param <- 3

separate.model.data <- list(N = nrow(data.joined.stan),
                            K = length(unique(data.joined.stan$REGION)),
                            x = data.joined.stan$REGION,
                            
                            SAT_ALL = data.joined.stan$SAT_ALL,
                            MD_FAMINIC = data.joined.stan$MD_FAMINC,
                            COSTT4_A = data.joined.stan$COSTT4_A,
                            POVERTY_RATE = data.joined.stan$POVERTY_RATE,
                            URBAN = data.joined.stan$URBAN,
                            PRIVATE = data.joined.stan$PRIVATE,
                            y = data.joined.stan$MD_EARN_WNE_P10,
                            
                            pm_alpha = 0,
                            ps_alpha = 10000 * scale_param,
                            pm_SAT_ALL = 50,
                            ps_SAT_ALL = 500 * scale_param,
                            pm_MD_FAMINC = 0,
                            ps_MD_FAMINC = 100 * scale_param,
                            pm_COSTT4_A = 0,
                            ps_COSTT4_A = 500 * scale_param,
                            pm_POVERTY_RATE = 0,
                            ps_POVERTY_RATE = 2500 * scale_param,
                            pm_URBAN = 0,
                            ps_URBAN = 2500 * scale_param,
                            pm_PRIVATE = 0,
                            ps_PRIVATE = 2500 * scale_param,
                            pm_sigma = 10000 * scale_param,
                            ps_sigma = 10000 * scale_param
                            
)


separate.fit <- separate.model$sample(data = separate.model.data, seed = 1234, refresh = 1e3)

separate.fit$summary()

```

Summary of model fit for main parameters with narrow priors:

```{r, echo=FALSE, results = "hide", eval=FALSE}
separate.model <- cmdstan_model(stan_file = "./Stan/separate.stan")

scale_param <- 0.5

separate.model.data <- list(N = nrow(data.joined.stan),
                            K = length(unique(data.joined.stan$REGION)),
                            x = data.joined.stan$REGION,
                            
                            SAT_ALL = data.joined.stan$SAT_ALL,
                            MD_FAMINIC = data.joined.stan$MD_FAMINC,
                            COSTT4_A = data.joined.stan$COSTT4_A,
                            POVERTY_RATE = data.joined.stan$POVERTY_RATE,
                            URBAN = data.joined.stan$URBAN,
                            PRIVATE = data.joined.stan$PRIVATE,
                            y = data.joined.stan$MD_EARN_WNE_P10,
                            
                            pm_alpha = 0,
                            ps_alpha = 10000 * scale_param,
                            pm_SAT_ALL = 50,
                            ps_SAT_ALL = 500 * scale_param,
                            pm_MD_FAMINC = 0,
                            ps_MD_FAMINC = 100 * scale_param,
                            pm_COSTT4_A = 0,
                            ps_COSTT4_A = 500 * scale_param,
                            pm_POVERTY_RATE = 0,
                            ps_POVERTY_RATE = 2500 * scale_param,
                            pm_URBAN = 0,
                            ps_URBAN = 2500 * scale_param,
                            pm_PRIVATE = 0,
                            ps_PRIVATE = 2500 * scale_param,
                            pm_sigma = 10000 * scale_param,
                            ps_sigma = 10000 * scale_param
                            
)


separate.fit <- separate.model$sample(data = separate.model.data, seed = 1234, refresh = 1e3)

separate.fit$summary()

```

## Pooled model

Summary of model fit for main parameters with wide priors:

```{r, echo=FALSE, results = "hide", eval=FALSE}
pooled.model <- cmdstan_model(stan_file = "./Stan/pooled.stan")

scale_param <- 3

pooled.model.data <- list(N = nrow(data.joined.stan),
                          
                          SAT_ALL = data.joined.stan$SAT_ALL,
                          MD_FAMINIC = data.joined.stan$MD_FAMINC,
                          COSTT4_A = data.joined.stan$COSTT4_A,
                          POVERTY_RATE = data.joined.stan$POVERTY_RATE,
                          URBAN = data.joined.stan$URBAN,
                          PRIVATE = data.joined.stan$PRIVATE,
                          y = data.joined.stan$MD_EARN_WNE_P10,
                          
                          pm_alpha = 0,
                          ps_alpha = 10000 * scale_param,
                          pm_SAT_ALL = 50,
                          ps_SAT_ALL = 500 * scale_param,
                          pm_MD_FAMINC = 0,
                          ps_MD_FAMINC = 100 * scale_param,
                          pm_COSTT4_A = 0,
                          ps_COSTT4_A = 500 * scale_param,
                          pm_POVERTY_RATE = 0,
                          ps_POVERTY_RATE = 2500 * scale_param,
                          pm_URBAN = 0,
                          ps_URBAN = 2500,
                          pm_PRIVATE = 0,
                          ps_PRIVATE = 2500 * scale_param,
                          pm_sigma = 10000 * scale_param,
                          ps_sigma = 10000 * scale_param
                          
                          )


pooled.fit <- pooled.model$sample(data = pooled.model.data, seed = 1234, refresh = 1e3)

pooled.fit$summary()

```

Summary of model fit for main parameters with narrow priors:

```{r, echo=FALSE, results = "hide", eval=FALSE}
pooled.model <- cmdstan_model(stan_file = "./Stan/pooled.stan")

scale_param <- 0.5

pooled.model.data <- list(N = nrow(data.joined.stan),
                          
                          SAT_ALL = data.joined.stan$SAT_ALL,
                          MD_FAMINIC = data.joined.stan$MD_FAMINC,
                          COSTT4_A = data.joined.stan$COSTT4_A,
                          POVERTY_RATE = data.joined.stan$POVERTY_RATE,
                          URBAN = data.joined.stan$URBAN,
                          PRIVATE = data.joined.stan$PRIVATE,
                          y = data.joined.stan$MD_EARN_WNE_P10,
                          
                          pm_alpha = 0,
                          ps_alpha = 10000 * scale_param,
                          pm_SAT_ALL = 50,
                          ps_SAT_ALL = 500 * scale_param,
                          pm_MD_FAMINC = 0,
                          ps_MD_FAMINC = 100 * scale_param,
                          pm_COSTT4_A = 0,
                          ps_COSTT4_A = 500 * scale_param,
                          pm_POVERTY_RATE = 0,
                          ps_POVERTY_RATE = 2500 * scale_param,
                          pm_URBAN = 0,
                          ps_URBAN = 2500,
                          pm_PRIVATE = 0,
                          ps_PRIVATE = 2500 * scale_param,
                          pm_sigma = 10000 * scale_param,
                          ps_sigma = 10000 * scale_param
                          
                          )


pooled.fit <- pooled.model$sample(data = pooled.model.data, seed = 1234, refresh = 1e3)

pooled.fit$summary()

```

## Hierarchical model

Summary of model fit for main parameters with wide priors:

```{r, echo=FALSE, results = "hide", message=FALSE, warning = FALSE, eval = FALSE}

hierarchical.model <- cmdstan_model(stan_file = "./Stan/hierarchical.stan")

scale_param <- 3

hierarchical.model.data <- list(N = nrow(data.joined.stan),
                                K = length(unique(data.joined.stan$REGION)),
                                x = data.joined.stan$REGION,
                            
                                SAT_ALL = data.joined.stan$SAT_ALL,
                                MD_FAMINIC = data.joined.stan$MD_FAMINC,
                                COSTT4_A = data.joined.stan$COSTT4_A,
                                POVERTY_RATE = data.joined.stan$POVERTY_RATE,
                                URBAN = data.joined.stan$URBAN,
                                PRIVATE = data.joined.stan$PRIVATE,
                                y = data.joined.stan$MD_EARN_WNE_P10,
                                
                                pm_alpha = 0,
                                ps_alpha = 10000 * scale_param,
                                pm_s_alpha = 100,
                                ps_s_alpha = 100 * scale_param,
                                
                                pm_SAT_ALL = 43,
                                ps_SAT_ALL = 500 * scale_param,
                                pm_s_SAT_ALL = 100,
                                ps_s_SAT_ALL = 100 * scale_param,
                                
                                pm_MD_FAMINC = 0,
                                ps_MD_FAMINC = 100 * scale_param,
                                pm_s_MD_FAMINC = 10,
                                ps_s_MD_FAMINC = 100 * scale_param,
                                
                                pm_COSTT4_A = 0,
                                ps_COSTT4_A = 500 * scale_param,
                                pm_s_COSTT4_A = 50,
                                ps_s_COSTT4_A = 500 * scale_param,
                                
                                pm_POVERTY_RATE = 0,
                                ps_POVERTY_RATE = 2500 * scale_param,
                                pm_s_POVERTY_RATE = 500,
                                ps_s_POVERTY_RATE = 500 * scale_param,
                                
                                pm_URBAN = 0,
                                ps_URBAN = 2500 * scale_param,
                                pm_s_URBAN = 500,
                                ps_s_URBAN = 500 * scale_param,
                                
                                pm_PRIVATE = 0,
                                ps_PRIVATE = 2500 * scale_param,
                                pm_s_PRIVATE = 500,
                                ps_s_PRIVATE = 500 * scale_param,
                                
                                pm_sigma = 10000,
                                ps_sigma = 10000 * scale_param,
                                pm_s_sigma = 500,
                                ps_s_sigma = 500 * scale_param)

hierarchical.fit <- hierarchical.model$sample(data = hierarchical.model.data, 
                                              seed = 1234, refresh = 1e3)

hierarchical.fit$summary()


```


Summary of model fit for main parameters with narrow priors:

```{r, echo=FALSE, results = "hide", message=FALSE, warning = FALSE, eval = FALSE}

hierarchical.model <- cmdstan_model(stan_file = "./Stan/hierarchical.stan")

scale_param <- 0.5

hierarchical.model.data <- list(N = nrow(data.joined.stan),
                                K = length(unique(data.joined.stan$REGION)),
                                x = data.joined.stan$REGION,
                            
                                SAT_ALL = data.joined.stan$SAT_ALL,
                                MD_FAMINIC = data.joined.stan$MD_FAMINC,
                                COSTT4_A = data.joined.stan$COSTT4_A,
                                POVERTY_RATE = data.joined.stan$POVERTY_RATE,
                                URBAN = data.joined.stan$URBAN,
                                PRIVATE = data.joined.stan$PRIVATE,
                                y = data.joined.stan$MD_EARN_WNE_P10,
                                
                                pm_alpha = 0,
                                ps_alpha = 10000 * scale_param,
                                pm_s_alpha = 100,
                                ps_s_alpha = 100 * scale_param,
                                
                                pm_SAT_ALL = 43,
                                ps_SAT_ALL = 500 * scale_param,
                                pm_s_SAT_ALL = 100,
                                ps_s_SAT_ALL = 100 * scale_param,
                                
                                pm_MD_FAMINC = 0,
                                ps_MD_FAMINC = 100 * scale_param,
                                pm_s_MD_FAMINC = 10,
                                ps_s_MD_FAMINC = 100 * scale_param,
                                
                                pm_COSTT4_A = 0,
                                ps_COSTT4_A = 500 * scale_param,
                                pm_s_COSTT4_A = 50,
                                ps_s_COSTT4_A = 500 * scale_param,
                                
                                pm_POVERTY_RATE = 0,
                                ps_POVERTY_RATE = 2500 * scale_param,
                                pm_s_POVERTY_RATE = 500,
                                ps_s_POVERTY_RATE = 500 * scale_param,
                                
                                pm_URBAN = 0,
                                ps_URBAN = 2500 * scale_param,
                                pm_s_URBAN = 500,
                                ps_s_URBAN = 500 * scale_param,
                                
                                pm_PRIVATE = 0,
                                ps_PRIVATE = 2500 * scale_param,
                                pm_s_PRIVATE = 500,
                                ps_s_PRIVATE = 500 * scale_param,
                                
                                pm_sigma = 10000,
                                ps_sigma = 10000 * scale_param,
                                pm_s_sigma = 500,
                                ps_s_sigma = 500 * scale_param)

hierarchical.fit <- hierarchical.model$sample(data = hierarchical.model.data, 
                                              seed = 1234, refresh = 1e3)

hierarchical.fit$summary()


```

# 11. Discussion of Issues and Potential Improvements.

During the project, the large amount of variables also posed challenges, as it was arguably rather slow and burdensome to find the most relevant variables to use in our analysis. It was somewhat surprising how fast the observation count started to shrink in data cleaning process, so in hindsight more attention could have been paid to cleanliness, as this dataset had for example a lot of missing values.

It was a shame we couldn't use a larger testing dataset because all data used for testing would be away from training the model. We tried to reduce the need to have a very long dataset by working very hard on removing independent variables. That work also ended up expanding our observation count from roughly 200 to over 700 observations, as we found variables with less null values and removed variables with too much missing data. For the feature selection, with more time we could have experimented with  alternative methods, like the LASSO or Ridge regression.

As we were building a predictive model, we had to take certain ethical questions into account, especially to avoid building a discriminatory model. For example, if our model was used to by an employer to assess how well alumni from a certain school would perform in their career, it would be discriminatory to have a model that predicts lower performance for a university with say, high female or black student population as the real reason for differences in our data might be something else entirely than skin color or gender.
In the end, this wasn't a big issue as for example the correlations between both gender vs income and share of white population vs income were very low and they would have been dropped from our model no matter what.

**VOISI EHKÄ MAINITA JOTAIN PREDICTIVE ASSESSMENTISTA, ESIM. KAIKILLE MALLEILLE JONKUNLAINEN ASSESSMENT TAI MONIPUOLISEMPI**


# 12. Conclusions

# 13. Self-reflection

In hindsight taking on a task of creating three multivariate models was very ambitious, because multivariable models had not been covered very much during the course. That ambition paid off, however, and we think we have now a much stronger grasp of how the different models - pooled, separate and hierarchical - work and also know how to build multivariate bayesian linear models in general. We also learned a lot about feature selection, because the 3000 variables in the dataset forced us to create sensible procedures for selection. The combination of using logic and feature engireering tools like stepwise regression is a very powerful skill we developed while making this project.

I think this project made us think really hard about what do we want to show the reader to make our work as understandable as possible and we learned to visualize data and results in interesting ways and apply the visualization techniques covered on the course. Making the visualizations also aided our own thinking and certain visualizations gave valuable insight on our results and their quality. 

Working with Stan is something none of us had done before this course. Stan is clearly a very powerful tool for statistical and data science use and we feel this project really ingrained basic Stan workflows and made working with Stan feel more of an efficient routine than an obstacle.
 
# 14. References

Card, D. (1999). THE CAUSAL EFFECT OF EDUCATION ON EARNINGS.
Wolla, S. A., & Sullivan, J. (2017). Education, Income, and Wealth. https://fred.stlouisfed.org/graph/?g=7yKu.

Data Commons. (2020). Gross domestic product per capita in United States of America [Graph]. 
Retrieved from https://datacommons.org/place/country/USA?utm_medium=explore&mprop=income&popt=Person&cpv=age%2CYears15Onwards&hl=en

Gelman, Andrew, and Jennifer Hill. Data analysis using regression and multilevel/hierarchical models. Cambridge university press, 2006.

Gabry, Gelman, Vehtari. (2016) Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC.

Number2. (2020). Average SAT Score [Blog Post].
Retrieved from: https://www.number2.com/average-sat-score/

Stan. (n.d) LOO package glossary [Website].
Retrieved from: ttps://mc-stan.org/loo/reference/loo-glossary.html

Stan. (n.d) Effective Sample Size [Website].
Retrieved from: https://mc-stan.org/docs/2_19/reference-manual/effective-sample-size-section.html

# 15. Appendix

## Stepwise regression 

```{r, warning = FALSE}

# baseline model
model <- lm(MD_EARN_WNE_P10 ~ ., data = data.joined.model)

# step wise regression implied "best" model in terms of AIC
step(model, direction = "backward")

# step wise second iteration without MASTER and DOCTORAL

data.stepwise <- select(data.joined.model, -c(MASTER, DOCTORAL))

model <- lm(MD_EARN_WNE_P10 ~ ., data = data.stepwise)

# step wise regression implied "best" model in terms of AIC
step(model, direction = "backward")

```

## HMC diagnostics output

```{r}

separate.fit$cmdstan_diagnose()

pooled.fit$cmdstan_diagnose()

hierarchical.fit$cmdstan_diagnose()

``` 

# K hat

```{r}

pareto_k_table(separate.fit$loo())

pareto_k_table(pooled.fit$loo())

pareto_k_table(hierarchical.fit$loo())

``` 