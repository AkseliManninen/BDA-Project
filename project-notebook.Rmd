---
title: "BDA Project"
author: "Niko Miller, Akseli Manninen and Santeri Löppönen"
output:
  pdf_document:
    toc: yes
    toc_depth: 1
  word_document:
    toc: yes
    toc_depth: '1'
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(aaltobda)
library(tidyverse)
library(latex2exp)
library(loo)
library(bayesplot)
library(posterior)
library(cmdstanr)
library(rstan)
library(tidyverse)
library(reshape2)
library(ggcorrplot)
set_cmdstan_path('/coursedata/cmdstan')

```

\newpage
# 1. Project Description and Motivation

Studying the relationship between income and education has been the focus on many studies. The studies have 
concluded that a strong connection exists between higher education and income (Card, 1999). In general, 
individuals with stronger education are more likely to be employed and earn a big salary compared to less 
educated people (Card, 1999). For that reason, education is described as an investment in human capital 
(Wolla & Sullivan, 2017). 

This study examines this phenomenon from the perspective of people that have acquired their education
from colleges in the United States. As the connection between education and income has been
shown in the existing literature, this study strives to further examine the associations between college related
features and income level years after graduation. This project is not limited to only 
considering educational aspects but expands it to family backgrounds.

In this study, a Bayesian approach is taken to observe the bond between the educational and family related 
features and earnings. It is in our interest to find out how accurately the selected features can predict future 
income for the students. Furthermore, finding well-predictive features among the vast number of variables is pursed, and then evaluating
predictive performance using these features with a selected statistical models.

As this study is conducted in a university environment by university students and presented mainly to other students and faculty, 
the findings of this study could be especially meaningful for the members of the group and peers on the course.

# 2. Data and the analysis problem

The used dataset is the most recent institutional-level college scorecard data from the US Department of Education. 
The institutional-level dataset contains aggregate data for each educational institution and includes data on 
institutional characteristics, enrollment, student aid, costs and student outcomes. 
The dataset has over 6000 observations on more than 3000 variables.

This dataset was chosen because it seemed to provide information that could answer
interesting education-related questions in the project, and also because the dataset 
has a large number of observations and a large number of variables. The large amount 
of variables permits for a lot of flexibility when it comes to modelling with the data 
and also having enough data is important in order to be able to make valid inferences. 
*During the project, the large amount of variables also posed challenges, as it 
was arguably rather slow and burdensome to find the most relevant variables to use in our analysis. 
It was somewhat surprising how fast the observation count started to shrink in data cleaning process, 
so in hindsight more attention could have been paid to cleanliness, as this dataset had for example a lot of missing values.* - DISCUSSIONIIN?

After investigating the dataset, the most intriguing analysis problem was to
study how college related factors affect the median earnings 10 years after entry.

```{r}
# read in data sets
data <- read.csv2("./Data/Most-Recent-Cohorts-Institution.csv", 
                  sep = ",", fileEncoding="UTF-8-BOM") %>% as_tibble()
data.description <- read.csv2("./Data/CollegeScorecardDataDictionary.csv", 
                              sep = ",", fileEncoding="UTF-8-BOM") %>% as_tibble()
```

## Feature selection

## Phase 1 - Feature selection based on literature and domain knowledge

The initial data set had more than 3000 features and in that regards, the number
of observations is relatively small (a relatively wide dataset). There are also a lot of missing values
in the data set and some features are missing. For these reasons, there was
a need to prune features.

The used process of feature selection consisted of two phases: In the first phase,
*a subset of features was select based on the features used in the existing 
literature* - LÄHDE? and using domain knowledge. From the potential features, only those
having enough data were included in the subset and others were discarded.

*The selected features in the first phase were* - DEPENDENT MUUTTUJA EI LIENE FEATURE? VOISI EHKÄ TEHDÄ ERILLISEN KAPPALEEN MISSÄ SELITETÄÄN ETTÄ Y MUUTTUJA ON MEDIAN EARNINGS JA KERROTAAN PERUSTELUT MIKSI JUURI SE. SITTEN SIIRRYTTÄISIIN FEATURES, ELI PREDICTOREIHIN: 

$$
\begin{array} {c|c|c|c|c|c|c|c} & Name & Type & Description \\ 
\hline
1 & SATVRMID & numerical & Midpoint\:of\:SAT\:scores\:at\:the\:institution\:(critical\:reading) \\
2 & SATMTMID & numerical & Midpoint\:of SAT scores at the institution (math) \\
3 & SATWRMID & numerical & Midpoint\:of\:SAT\:scores\:at\:the\:institution\:(writing) \\
4 & MD\_FAMINC & numerical & Median\:family\:income \\
5 & AGE\_ENTRY & numerical & Average\:age\:of\:entry \\
6 & FEMALE & numerical & Share\:of\:female\:students \\
7 & FIRST\_GEN & numerical & Share\:of\:first-generation students \\
8 & PCT\_WHITE & numerical & Percent\:of\:the\:population\:from\:students'\:zip\:codes\:that\:is\:White \\
9 & DEBT\_MDN\_SUPP & numerical & Median\:debt,\:suppressed\:for\:n=30 \\
10 & C150\_4 & numerical & Completion\:rate\:for\:first-time,\:full-tim\:students \\
11 & COSTT4\_A & numerical & Average\:cost\:of\:attendance\:(academic\:year\:institutions) \\
12 & POVERTY\_RATE & numerical & Poverty\:rate \\
13 & UNEMP\_RATE & numerical & Unemployment\:rate \\
14 & MARRIED & numerical & Share\:of\:married students \\
15 & VETERAN & numerical & Share\:of\:veteran students \\
16 & LOCALE & categorical & Locale\:of\:institution \\
17 & CCBASIC & categoriacal & Carnegie\:Classification -- basic \\
18 & CONTROL & categorical & Control\:of\:institution \\
19 & MD\_EARN\_WNE\_P10 & numerical & Median\:earnings\:of\:students\:10\:years\:after\:entry\\
\end{array}
$$

## Code for extracting the feature subset

```{r, warning = FALSE}

# DATA MANIPULATION ----

# list variables
id.vars <- c("UNITID", "INSTNM", "CITY", "ST_FIPS", "REGION")
numerical.vars <- c("SATVRMID", "SATMTMID", "MD_FAMINC", "AGE_ENTRY", "FEMALE", 
                    "FIRST_GEN", "PCT_WHITE", "DEBT_MDN_SUPP", "C150_4", "COSTT4_A", 
                    "MD_EARN_WNE_P10", "POVERTY_RATE", "UNEMP_RATE", "MARRIED")
categorical.vars <- c("LOCALE", "CCBASIC", "CONTROL")
SAT.vars <- c("SATVRMID", "SATMTMID")

# filter specific school types
schooltype.filter <- seq(14,23)

# create map for variable descriptions
variable.descriptions <- data.description %>%
  select(VARIABLE.NAME, NAME.OF.DATA.ELEMENT, NOTES) %>%
  filter(VARIABLE.NAME %in% c(id.vars, categorical.vars, numerical.vars))

# extract categorical variables
data.categorical <- data %>%
  select(all_of(id.vars), all_of(categorical.vars)) %>%
  mutate(across(.cols = all_of(categorical.vars), .fns = as.factor))

data.categorical.dropna <- data.categorical %>%
  drop_na()

# extract numerical variables
data.numerical <- data %>%
  select(all_of(id.vars), all_of(numerical.vars)) %>%
  mutate(across(.cols = c(id.vars[1], numerical.vars), .fns = as.numeric))

data.numerical.dropna <- data.numerical %>%
  drop_na()

# aggregate SAT scores
data.numerical.dropna <- data.numerical.dropna %>%
  mutate(SAT_ALL = data.numerical.dropna %>%
           select(SATVRMID, SATMTMID) %>%
           rowMeans()
         )

data.joined <- data.numerical %>%
  inner_join(data.categorical, by = id.vars) %>%
  filter(CCBASIC %in% schooltype.filter)

data.joined.dropna <- data.numerical.dropna %>%
  inner_join(data.categorical.dropna, by = id.vars) %>%
  filter(CCBASIC %in% schooltype.filter)

categorical.vars.data <- data.joined.dropna %>%
  select(all_of(categorical.vars), MD_EARN_WNE_P10) %>%
  relocate(MD_EARN_WNE_P10, 1)


data.joined <- data.numerical %>%
  inner_join(data.categorical, by = id.vars) %>%
  filter(CCBASIC %in% schooltype.filter)

data.joined.dropna <- data.numerical.dropna %>%
  inner_join(data.categorical.dropna, by = id.vars) %>%
  filter(CCBASIC %in% schooltype.filter)

```

## Phase 2 - Feature selection with correlation and visual dependency

In the second phase of feature selection, a subset of features was selected
from the 18 variables of the first phase. The correlations between the features 
were examined as well as their associations to the dependent variable.

## Numerical variables

SAT scores were combined as one variable, because they were correlated and
viewed as one entity. However, writing SAT scores had too few observations,
due to discontinued tracking, so the variable SAT_ALL was formed by summing the 
math and critical thinking SAT scores. SAT scores were included
because the correlation was high with the dependent variable.

For the rest of the numerical variables, if the correlation between a feature
and the dependent variable was low and there was no observable dependency 
between the two in the scatter plot, the feature was excluded. To avoid multicollinearity,
we removed independent variables that were highly correlated with other independent variables,
especially if they were not clearly correlated with the dependent variable and we couldn't
form a believable hypothesis for the mechanism through which that variable affected income after
college.

The selected numerical variables were: SAT_ALL (median sum of math and critical thinking SAT scores), 
MD_FAMINIC (median family income of the student), AGE_ENTRY (median age of starting at the college), 
COSTT4_A (median cost of college), and POVERTY_RATE (poverty rate in the area the college is located).

## Visualizing correlations and data points with the dependent variable.

```{r, warning = FALSE}

# PRELIMINARY ANALYSIS ----

# make variable type specific data frames for plots etc.
numerical.vars.data <- data.joined.dropna %>% select(!c(id.vars, 
  categorical.vars, SAT.vars)) %>% relocate(MD_EARN_WNE_P10, 1)

categorical.vars.data <- data.joined.dropna %>%
  select(all_of(categorical.vars), MD_EARN_WNE_P10) %>%
  relocate(MD_EARN_WNE_P10, 1)

# Correlation plot
ggcorrplot(cor(numerical.vars.data),
          lab = TRUE,
          lab_size = 2,
          title = "Correlations",
          tl.cex = 8,
          )

```

```{r, fig.height=12, fig.width=12}

melted.numerical.vars.data <- melt(numerical.vars.data, id.vars = "MD_EARN_WNE_P10")

melted.numerical.vars.data <- melt(numerical.vars.data, id.vars = "MD_EARN_WNE_P10")
ggplot(melted.numerical.vars.data, aes(x = value, y = MD_EARN_WNE_P10)) + 
  facet_wrap(~variable, scales = "free", ncol = 3) +
  geom_point(shape=20, color="black") +
  ggtitle("Median earnings after 10 years and the independent variables") +
  xlab("Feature value") + ylab("Median earnings")

```


## Categorical variables

The categorical variables were visualized with box plots to see if income after
college differed among the categories. Based on an analysis on the variable LOCALE
(whether college located in metropolis, city, suburb, town, or rural area) a new 
binary variable URBAN was generated, where value 1 represents any area that is not
categorized as rural.

The categorical variable CCBASIC which represented the Carnegie Classification
was divided into two binary MASTER and DOCTORL. These variables represent
if the college is classified as Master's college and university or Doctoral's
college and university. If a college does not belong to either of those,
it is a Bachelor's college and university. Other special focus colleges
and universities were discarded from the dataset to keep the model more simple
and avoid unnecessary outliers due to unconventional nature of some very specialized 
colleges. Our model does not attempt to provide accurate predictions for
specialized colleges.

The categorical variable CONTROL had three classes: public, for-profit private and 
nonprofit private. CONTROL was modified into a binary variable PRIVATE representing 
if the school is private or public school. There were only few non-profit private 
observations, so those were merged together with the private observations.

The selected categorical variables were: URBAN, DOCTORAL, MASTER, PRIVATE.

```{r, warning = FALSE}

# categorical variable box plots
melted.categorial <- melt(categorical.vars.data, id.vars = "MD_EARN_WNE_P10")
melted.categorial.ccbasic <- melted.categorial %>% as_tibble() %>% filter(variable=="CCBASIC")
melted.categorial.control <- melted.categorial %>% as_tibble() %>% filter(variable=="CONTROL")
melted.categorial.locale <- melted.categorial %>% as_tibble() %>% filter(variable=="LOCALE")

ggplot(melted.categorial.ccbasic, aes(x=value, y=MD_EARN_WNE_P10, fill=value)) +
  geom_boxplot() +
  geom_jitter(color="black", size=0.4, alpha=0.9) +
  theme(
    legend.position="none",
    plot.title = element_text(size=11)
  ) +
  ggtitle("University types") +
  xlab("CCBASIC") +
  labs(caption = "Doctoral (15-17), Master's (18-20), Bachelor's (21-23)")

ggplot(melted.categorial.control, aes(x=value, y=MD_EARN_WNE_P10, fill=value)) +
  geom_boxplot() +
  geom_jitter(color="black", size=0.4, alpha=0.9) +
  theme(
    legend.position="none",
    plot.title = element_text(size=11)
  ) +
  ggtitle("Public vs. Private") +
  xlab("CONTROL") +
  scale_x_discrete(labels = c("Public","Private, Nonprofit","Proprietary"))

ggplot(melted.categorial.locale, aes(x=value, y=MD_EARN_WNE_P10, fill=value)) +
  geom_boxplot() +
  geom_jitter(color="black", size=0.4, alpha=0.9) +
  theme(
    legend.position="none",
    plot.title = element_text(size=11)
  ) +
  ggtitle("Location of school") +
  xlab("LOCALE") +
  labs(caption = "City (11-13), Suburb (21-23), Town (31-33), Rural (41-43)")

```

## Phase 3 - Feature selection with stepwise regression

In the third phase, the remaining variables were used with stepwise regression,
to test which subset of features perform the best, whether the received 
coefficients are reasonable, and if there are signs of overfitting.

The Stepwise regression suggested using all of the variables, except CITY
and DOCTORAL. The stepwise regression can be seen in appendix 1. Because stepwise
regression suggested leaving out DOCTORAL, for the sake of consistency we decided
to also leave out MASTER as it was a the middle level in our institutional 
classifications and wouldn't have made much sense on its own.

The final features are listed in the table below:

$$
\begin{array} {c|c|c|c|c|c|c|c} & Name & Data\:type & Description \\ 
\hline
1 & SAT\_ALL & float & Midpoint\:of\:SAT\:scores\:at\:the\:institution\:(critical\:reading\:,math) \\
2 & MD\_FAMINC & float & Median\:family\:income \\
3 & AGE\_ENTRY & float & Average\:age\:of\:entry \\
4 & COSTT4\_A & float & Average\:cost\:of\:attendance\:(academic\:year\:institutions) \\
5 & POVERTY\_RATE & float & Poverty\:rate \\
6 & PRIVATE & binary & Carnegie\:Classification -- basic \\
7 & MD\_EARN\_WNE\_P10 & float & Median\:earnings\:of\:students\:10\:years\:after\:entry\\
\end{array}
$$


## Generating binary features from the categorical features

```{r, warning = FALSE}
data.joined.model <- data.joined.dropna %>%
  mutate(URBAN = case_when(LOCALE %in% c(seq(11,13), seq(21,23)) ~ 1,
                           TRUE ~ 0),
         PRIVATE = case_when(CONTROL %in% c(2,3) ~ 1,
                             TRUE ~ 0),
         DOCTORAL = case_when(CCBASIC %in% seq(15,17) ~ 1,
                              TRUE ~ 0),
         MASTER = case_when(CCBASIC %in% seq(18,20) ~ 1,
                            TRUE ~ 0)
  )


numerical.vars.model <- c("MD_EARN_WNE_P10", "SAT_ALL", "MD_FAMINC", "AGE_ENTRY", 
                          "COSTT4_A", "POVERTY_RATE")
categorical.vars.model <- c("URBAN", "PRIVATE", "DOCTORAL", "MASTER")

# data with REGION identifier for STAN
data.joined.stan <- data.joined.model %>%
  select(REGION, numerical.vars.model, categorical.vars.model)

# data for linear regression model in R
data.joined.model <- data.joined.stan %>%
    select(-REGION)

```

# 3. Description of the models

MATEMATIIKKA TARKISTETTAVA

## Description of the separate model

In the separate model, posteriors for the parameters are constructed. In
the context of the project, the separate model considers all regions independent
from each other, meaning that each region have individual parameters (mu, sigma).

Mathematical description:

$y_{ij}|\mu_j, \sigma_j \sim \mathcal{N}(\mu_j, \sigma_j^2)$ 

where $\mu_j = \alpha_j+\bf{\beta_j X}$

The parameters of the parameter vector are given in the section 4 with their
priors.

## Description of the pooled model

As in the separate model, the pooled model constructs posteriors for the 
parameters. However, the regions are considered as one entity meaning that
all regions share the same distribution and parameter values.

Mathematical description:

$y_i|\mu, \sigma \sim \mathcal{N}(\mu, \sigma^2)$

where $\mu = \alpha+\bf{\beta X}$

The parameters of the parameter vector are given in the section 4 with their
priors.

## Description of the hierarchical model

Contrary to the other two models, in the hierarchical model posteriors
are constructed for the prior parameters. With the hierarchical model,
the regions are considered as individual but similar. In the context of the
project, the regions share same sigma and the parameters forming mu are similarly
distributed (sharing the hyperparameters).

Mathematical description:

$y_{ij} | \mu_j \sim \mathcal{N}(\mu_j, \sigma^2)$

where $\mu_j|\mu_P, \sigma_P^2 \sim \mathcal{N}(\mu_P, \sigma_P^2)$

The hyperparameters and parameters are given in the section 4 with their priors.

## Description of the linear model

# 4. Informative or weakly informative priors, and justification of their choices.

We use weakly informative priors, as we do not posses enough information about the 
dependency between the independent variables and the dependent variable. 
When selecting the priors, proper distribution type was considered for each variable. 
The prior standard deviations were selected based on the magnitude of absolute values 
of the variables and what kind of impact they could have for income, with loose enough
estimates to avoid limiting the values too much. Alternative approach could have been 
to standardize all variables, which would have reduced the need to think about magnitudes
of absolute values.

SAT_ALL ~ Normal(43, 500)

Justification: We agreed that it was somewhat reasonable to expect scores in the SAT 
exam to be associated with higher income. Due to our approach of using weakly informative 
priors, we set a high standard deviation, but set a positive mean due to expected positive
association.

The mean is calculated with the following formula: Median individual income
in the United States / Average SAT Score (math and writing).

The median individual income in the US was approximately 31 000 in 2020 
(Data Commons, 2020). The average SAT score in the US in 2020 were 523 in Math
and 582 in Evidence-Based Reading and Writing (Number2, 2020).

mu = 31 000 / (523 + 528/2) = 43.2

MD_FAMINIC ~ Normal(0, 100)

Justification: Weakly informative prior is again selected as we don't posses enough 
information on the dependency. The absolute values are in general high, 
(for example compared to AGE_OF_ENTRY) and thus the standard deviation is set 
lower for this variable. However, there could be cases where MD_FAMINIC is low, 
due to for example unemployment, so the standard deviation is still set 
considerably high. 

## Ehdotus
This is a variable we will try to transform to logarithmic scale as impact of say, 
10 000$ more income can be far greater for a low-income family than for a high-income family.

AGE_ENTRY ~ Normal(0, 2500)

Justification: We don't have a strong expectation of direction or magnitude of effect on income. 
As the age of entry could be somewhere in the range of 15 - 50 without considering outliers, 
a few dozen years difference could have dramatic changes in income either way, the standard
deviation is set high.


COSTT4_A ~ Normal(0, 500)

Justification: Weakly informative prior is selected as we don't posses enough 
information on the dependency. The average cost per academic year is likely to take lower
values than median family income, but higher values than average age of entry and thus 
the standard deviation is set between the standard deviations of those.

POVERTY_RATE ~ Normal(0, 2500)

## Tää ei oikein täsmää. Jos tää sais ison painon pienillä arvoilla niin se tarkottais että kun liikutaan esim 2% köyhyydestä 3% köyhyyteen niin on tosi isot vaikutukset tuloihin. Todellisuudessa alueet on varmaan aika samanlaisia hyvinvoivia alueita. Nollaköyhyys on intercept-arvo josta sitten lähetään askeleittain kattomaan että miten tulot muuttuu kun alueen köyhyys lisääntyy. RATKAISUEHDOTUS: Lasketaan sd:tä. Ei tarvii olla yhtä dramaattinen kuin binäärisillä muutujilla.

Justification: The possible values are between 0 and 100. There could be situations were poverty rate in an area is really low, for instance 0.5%. For that reason, the standard deviation in the prior is set high to enable possibly high weight for a small value.

MASTER ~ Normal(0, 2500)

PRIVATE ~ Normal(0, 2500)

Justification: For MASTER and PRIVATE weakly informative prior, is selected as 
we don't posses enough information on the dependency with the dependent variable.
Because the values are always either 0 and 1, the standard deviation is set
high.

# 5. Stan, rstanarm or brms code.

## Separate model
```{r, results = "hide", eval=FALSE}

separate.model <- cmdstan_model(stan_file = "./Stan/separate.stan")

separate.model.data <- list(N = nrow(data.joined.stan),
                            K = length(unique(data.joined.stan$REGION)),
                            x = data.joined.stan$REGION,
                            
                            SAT_ALL = data.joined.stan$SAT_ALL,
                            MD_FAMINIC = data.joined.stan$MD_FAMINC,
                            AGE_ENTRY = data.joined.stan$AGE_ENTRY,
                            COSTT4_A = data.joined.stan$COSTT4_A,
                            POVERTY_RATE = data.joined.stan$POVERTY_RATE,
                            MASTER = data.joined.stan$MASTER,
                            PRIVATE = data.joined.stan$PRIVATE,
                            y = data.joined.stan$MD_EARN_WNE_P10,
                            
                            pm_alpha = 0,
                            ps_alpha = 10000,
                            pm_SAT_ALL = 50,
                            ps_SAT_ALL = 500,
                            pm_MD_FAMINC = 0,
                            ps_MD_FAMINC = 100,
                            pm_AGE_ENTRY = 0,
                            ps_AGE_ENTRY = 2500,
                            pm_COSTT4_A = 0,
                            ps_COSTT4_A = 500,
                            pm_POVERTY_RATE = 0,
                            ps_POVERTY_RATE = 2500,
                            pm_MASTER = 0,
                            ps_MASTER = 2500,
                            pm_PRIVATE = 0,
                            ps_PRIVATE = 2500,
                            pm_sigma = 10000,
                            ps_sigma = 10000
                            
)


separate.fit <- separate.model$sample(data = separate.model.data, seed = 1234, refresh = 1e3)

separate.fit

```


## Pooled model
```{r, results = "hide", eval=FALSE}

pooled.model <- cmdstan_model(stan_file = "./Stan/pooled.stan")

pooled.model.data <- list(N = nrow(data.joined.stan),
                          y = data.joined.stan$MD_EARN_WNE_P10,
                          SAT_ALL = data.joined.stan$SAT_ALL,
                          MD_FAMINIC = data.joined.stan$MD_FAMINC,
                          AGE_ENTRY = data.joined.stan$AGE_ENTRY,
                          COSTT4_A = data.joined.stan$COSTT4_A,
                          POVERTY_RATE = data.joined.stan$POVERTY_RATE,
                          MASTER = data.joined.stan$MASTER,
                          PRIVATE = data.joined.stan$PRIVATE)


pooled.fit <- pooled.model$sample(data = pooled.model.data, seed = 1234, refresh = 1e3)

pooled.fit

```

## Hierarchical model fit
```{r, results = "hide", message=FALSE, warning = FALSE, eval = FALSE}

hierarchical.model <- cmdstan_model(stan_file = "./Stan/hierarchical-akseli.stan")

hierarchical.model.data <- list(N = nrow(data.joined.stan),
             y = data.joined.stan$MD_EARN_WNE_P10,
             SAT_ALL = data.joined.stan$SAT_ALL,
             MD_FAMINIC = data.joined.stan$MD_FAMINC,
             AGE_ENTRY = data.joined.stan$AGE_ENTRY,
             COSTT4_A = data.joined.stan$COSTT4_A,
             POVERTY_RATE = data.joined.stan$POVERTY_RATE,
             MASTER = data.joined.stan$MASTER,
             PRIVATE = data.joined.stan$PRIVATE,
             K = length(unique(data.joined.stan$REGION)),
             x = data.joined.stan$REGION)

hierarchical.fit <- hierarchical.model$sample(data = hierarchical.model.data, 
                                              seed = 1234, refresh = 1e3)

hierarchical.fit
```


# 6. How to the Stan model was run, that is, what options were used. 
This is also more clear as combination of textual explanation and the actual code line.

# 7. Convergence diagnostics (Rˆ, ESS, divergences) and what was done if the convergence was not good with the first try.

## Separate model Rhat
```{r, eval = FALSE}

rhat.df <- tibble()

params <- c("alpha[1]", "beta_SAT_ALL[1]", "beta_MD_FAMINIC[1]", 
            "beta_AGE_ENTRY[1]", "beta_COSTT4_A[1]", "beta_POVERTY_RATE[1]", 
            "beta_MASTER[1]", "beta_PRIVATE[1]")

for (param in params) {
  rhats <- extract_variable_matrix(separate.fit$draws(), variable = param) %>% apply(2, rhat)
  row <- tibble("Parameter" = param, 
                "Chain 1" = rhats[1], 
                "Chain 2" = rhats[2], 
                "Chain 3" = rhats[3], 
                "Chain 4" = rhats[4])
  rhat.df <- rbind(rhat.df, row)
}

rhat.df

``` 


## Pooled model Rhat
```{r, eval=FALSE}

params <- pooled.model$variables()$parameters %>% names()
rhat.df <- tibble()
for (param in params) {
  rhats <- extract_variable_matrix(pooled.fit$draws(), variable = param) %>% apply(2, rhat)
  row <- tibble("Parameter" = param, 
                "Chain 1" = rhats[1], 
                "Chain 2" = rhats[2], 
                "Chain 3" = rhats[3], 
                "Chain 4" = rhats[4])
  rhat.df <- rbind(rhat.df, row)
}
rhat.df

```


## Hierarchical model Rhat
```{r, eval = FALSE}

rhat.df <- tibble()

params <- c("alpha[1]", "beta_SAT_ALL[1]", "beta_MD_FAMINIC[1]", 
            "beta_AGE_ENTRY[1]", "beta_COSTT4_A[1]", "beta_POVERTY_RATE[1]", 
            "beta_MASTER[1]", "beta_PRIVATE[1]")

for (param in params) {
  rhats <- extract_variable_matrix(hierarchical.fit$draws(), variable = param) %>% apply(2, rhat)
  row <- tibble("Parameter" = param, 
                "Chain 1" = rhats[1], 
                "Chain 2" = rhats[2], 
                "Chain 3" = rhats[3], 
                "Chain 4" = rhats[4])
  rhat.df <- rbind(rhat.df, row)
}

rhat.df

``` 

## Serparate Model Effective sample size (ESS)
```{r, eval = FALSE}

params <- separate.model$variables()$parameters %>% names()
ess.df <- tibble()

params <- c("alpha[1]", "beta_SAT_ALL[1]", "beta_MD_FAMINIC[1]", 
            "beta_AGE_ENTRY[1]", "beta_COSTT4_A[1]", "beta_POVERTY_RATE[1]", 
            "beta_MASTER[1]", "beta_PRIVATE[1]")

for (param in params) {
  ess <- extract_variable_matrix(separate.fit$draws(), variable = param) %>% apply(2, ess_basic)
  row <- tibble("Parameter" = param, 
                "ESS" = ess)
  ess.df <- rbind(ess.df, row)
}
ess.df <- ess.df  %>% group_by(Parameter) %>% summarise(ESS = sum(ESS)/n(),)

ess.df


``` 


## Pooled Model Effective sample size (ESS)
```{r, eval = FALSE}

#pooled.fit$cmdstan_summary()

params <- pooled.model$variables()$parameters %>% names()
ess.df <- tibble()

for (param in params) {
  ess <- extract_variable_matrix(pooled.fit$draws(), variable = param) %>% apply(2, ess_basic)
  row <- tibble("Parameter" = param, 
                "ESS" = ess)
  ess.df <- rbind(ess.df, row)
}
ess.df <- ess.df  %>% group_by(Parameter) %>% summarise(ESS = sum(ESS)/n(),)

ess.df

``` 

## Hierarchical Model Effective sample size (ESS)
```{r, eval = FALSE}

params <- hierarchical.model$variables()$parameters %>% names()
ess.df <- tibble()

params <- c("alpha[1]", "beta_SAT_ALL[1]", "beta_MD_FAMINIC[1]", 
            "beta_AGE_ENTRY[1]", "beta_COSTT4_A[1]", "beta_POVERTY_RATE[1]", 
            "beta_MASTER[1]", "beta_PRIVATE[1]")

for (param in params) {
  ess <- extract_variable_matrix(hierarchical.fit$draws(), variable = param) %>% apply(2, ess_basic)
  row <- tibble("Parameter" = param, 
                "ESS" = ess)
  ess.df <- rbind(ess.df, row)
}
ess.df <- ess.df  %>% group_by(Parameter) %>% summarise(ESS = sum(ESS)/n(),)

ess.df


``` 

## HMC specific convergence diagnostics for all models
```{r, eval = FALSE}

separate.fit$cmdstan_diagnose()

pooled.fit$cmdstan_diagnose()

hierarchical.fit$cmdstan_diagnose()

``` 

# 8. Posterior predictive checks and model comparison

## Posterior predictive checking
```{r, eval = FALSE}

separate.extract <- separate.fit$draws(variable = "y_rep")

y <- data.joined.stan$MD_EARN_WNE_P10

y_rep <- matrix(data = separate.extract[,1,], nrow = 1000)

separate.ppctitle <- ggtitle("Separate model",
                             "Comparing densities of y and y_rep")

ppc_dens_overlay(y, y_rep) + separate.ppctitle

# Pooled

pooled.extract <- pooled.fit$draws(variable = "y_rep")

y_rep <- matrix(data = pooled.extract[,1,], nrow = 1000)

pooled.ppctitle <- ggtitle("Pooled model",
                             "Comparing densities of y and y_rep")

ppc_dens_overlay(y, y_rep) + pooled.ppctitle

# Hierarchical

hierarchical.extract <- hierarchical.fit$draws(variable = "y_rep")

y_rep <- matrix(data = hierarchical.extract[,1,], nrow = 1000)

hierarchical.ppctitle <- ggtitle("Hierarchical model",
                             "Comparing densities of y and y_rep")

ppc_dens_overlay(y, y_rep) + hierarchical.ppctitle
```


## LOO (Model comparison)
```{r, eval = FALSE, warning = FALSE}

separate.loo <- separate.fit$loo()

pooled.loo <- pooled.fit$loo()

hierarchical.loo <- hierarchical.fit$loo()

loo_compare(separate.loo, pooled.loo, hierarchical.loo)

``` 

Based on LOO we should select... as it has the highest score

## K hat
```{r, eval = FALSE}

pareto_k_table(separate.fit$loo())

pareto_k_table(pooled.fit$loo())

pareto_k_table(hierarchical.fit$loo())

``` 

```{r, eval = FALSE, warning=FALSE}

plot(separate.fit$loo(), main = "Separate model PSIS diagnostics")
  
plot(pooled.fit$loo(), main = "Pooled model PSIS diagnostics")

plot(hierarchical.fit$loo(), main = "Hierarchical model PSIS diagnostics")

``` 

Based on $\hat{K}$ the predictions are ... too optimistic/reliable?
- Why pooled model looks like that - overfitting or something?


# 9. Optional/Bonus: Predictive performance assessment if applicable (e.g. classification accuracy) and evaluation 
of practical usefulness of the accuracy. This should be reported for all models as well.

# 10. Sensitivity analysis with respect to prior choices (i.e. checking whether the result changes a lot if prior 
is changed). This should be reported for all models.

Uniform priors were used for each model for sensitivity testing.

# 11. Discussion of issues and potential improvements.

- Correlation does not mean causality
- Ethics selecting features
- Selecting priors properly 

# 12. Conclusion what was learned from the data analysis.

# 13. Self-reflection of what the group learned while making the project.

- Multivariable regression
- Feature selection from a massive dataset
- Feature engineering
- Data visualization
- Stan workflow
 
# 14. References

Card, D. (1999). THE CAUSAL EFFECT OF EDUCATION ON EARNINGS.
Wolla, S. A., & Sullivan, J. (2017). Education, Income, and Wealth. https://fred.stlouisfed.org/graph/?g=7yKu.

Data Commons. (2020). Gross domestic product per capita in United States of America [Graph]. 
Retrieved from https://datacommons.org/place/country/USA?utm_medium=explore&mprop=income&popt=Person&cpv=age%2CYears15Onwards&hl=en

Number2. (2020). Average SAT Score [Blog Post].
Retrieved from: https://www.number2.com/average-sat-score/

# 15. Appendices

## Appendix 1 - Stepwise regression 
```{r, warning = FALSE}
# PRELIMINARY ANALYSIS ----
# preliminary model with all numerical vars (not yet categorical)
# MODELING ----

data.joined.model <- data.joined.dropna %>%
  mutate(URBAN = case_when(LOCALE %in% c(seq(11,13), seq(21,23)) ~ 1,
                           TRUE ~ 0),
         PRIVATE = case_when(CONTROL %in% c(2,3) ~ 1,
                             TRUE ~ 0),
         DOCTORAL = case_when(CCBASIC %in% seq(15,17) ~ 1,
                              TRUE ~ 0),
         MASTER = case_when(CCBASIC %in% seq(18,20) ~ 1,
                            TRUE ~ 0)
  )


numerical.vars.model <- c("MD_EARN_WNE_P10", "SAT_ALL", "MD_FAMINC", "AGE_ENTRY", 
                          "COSTT4_A", "POVERTY_RATE")
categorical.vars.model <- c("URBAN", "PRIVATE", "DOCTORAL", "MASTER")

# data with REGION identifier for STAN
data.joined.stan <- data.joined.model %>%
  select(REGION, numerical.vars.model, categorical.vars.model)

# data for linear regression model in R
data.joined.model <- data.joined.stan %>%
    select(-REGION)

# baseline model
model <- lm(MD_EARN_WNE_P10 ~ ., data = data.joined.model)
summary(model)

# step wise regression implied "best" model in terms of AIC
step(model, direction = "backward")
stepwise.model <- lm(formula = MD_EARN_WNE_P10 ~ SAT_ALL + MD_FAMINC + COSTT4_A + 
                       POVERTY_RATE + URBAN + PRIVATE + MASTER, data = data.joined.model)
summary(stepwise.model)
```

